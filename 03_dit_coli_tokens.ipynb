{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the tokens from a corpus\n",
    "\n",
    "This jupyter notebook has been used in DIT's Computational Linguistic course; session of 28th Feruary\n",
    "\n",
    "We are going to setup a toy corpus and compute some _similarities_.\n",
    "\n",
    "The libraries to be used today are:\n",
    "\n",
    "* [numpy](https://numpy.org/)\n",
    "* [pandas](https://pandas.pydata.org/)\n",
    "* [nltk](https://www.nltk.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Prerequisites\n",
    "\n",
    "Since we are going to use non-standard libraries, we need to set them up --if working on an ephemeral environment (e.g., colab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\paolo\\appdata\\roaming\\python\\python310\\site-packages (3.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\paolo\\appdata\\roaming\\python\\python310\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\paolo\\appdata\\roaming\\python\\python310\\site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\paolo\\appdata\\roaming\\python\\python310\\site-packages (from nltk) (2022.1.18)\n",
      "Requirement already satisfied: click in c:\\users\\paolo\\appdata\\roaming\\python\\python310\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\paolo\\appdata\\roaming\\python\\python310\\site-packages (from click->nltk) (0.4.4)\n",
      "Requirement already satisfied: wheel in c:\\users\\paolo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.37.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\paolo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.4.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\paolo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\paolo\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (1.22.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\paolo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\paolo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install nltk\n",
    "!pip install wheel\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Defining the preprocessing _pipeline_:\n",
    "\n",
    "1. Tokenisation\n",
    "2. Stemmming\n",
    "3. Stopwording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invoking the necessary objects\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'input', 'text', '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a tiny test\n",
    "tokenizer.tokenize(\"The input text.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'document'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(\"documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['persever', '(', 'nicknam', 'perci', ')', 'is', 'a', 'car-siz', 'mar', 'rover', 'design', 'to', 'explor', 'the', 'crater', 'jezero', 'on', 'mar', 'as', 'part', 'of', 'nasa', \"'s\", 'mar', '2020', 'mission', '.']\n"
     ]
    }
   ],
   "source": [
    "# both tokenisation and stemming\n",
    "text = \"\"\"Perseverance (nicknamed Percy) is a car-sized Mars \n",
    "rover designed to explore the crater Jezero on Mars as part \n",
    "of NASA's Mars 2020 mission.\"\"\"\n",
    "\n",
    "print([stemmer.stem(w) for w in tokenizer.tokenize(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\paolo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The first time you use the stopwords, you have to download them!\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = stopwords.words(\"english\")\n",
    "stop_words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a stopword?\n",
    "\n",
    "According to [the Wikipedia](https://en.wikipedia.org/wiki/Stop_word): in computing, stop words are words which are **filtered out** before or after processing of natural language data \\[...\\] the most common words in a language.\n",
    "\n",
    "\\[...\\]\n",
    "\n",
    "For some search engines, these are **some of the most common, short function words,** such as the, is, at, which, and on. In this case, stop words can cause problems when searching for phrases that include them, particularly in names such as \"The Who\", \"The The\", or \"Take That\". \n",
    "\n",
    "**Q: Can I create a list of stopwords on the fly?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Setting up the _corpus_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"thomas jefferson began building monticello at the age of 26.\\nconstruction was done mostly by local masons and carpenters.\\nhe moved into the south pavilion in 1770.\\nturning monticello into a neoclassical masterpiece was jefferson's obsession.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = \"\"\"Thomas Jefferson began building Monticello at the age of 26.\\n\"\"\"\n",
    "sentences += \"\"\"Construction was done mostly by local masons and carpenters.\\n\"\"\"\n",
    "sentences += \"He moved into the South Pavilion in 1770.\\n\"\n",
    "sentences += \"\"\"Turning Monticello into a neoclassical masterpiece was Jefferson's obsession.\"\"\"\n",
    "\n",
    "sentence = sentences.lower()\n",
    "sentence      # what is the diff wrt print()?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Bag of words representation\n",
    "\n",
    "Let us compute the BoW representation for our toy corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sent0': {'thoma': 1, 'jefferson': 1, 'began': 1, 'build': 1, 'monticello': 1, 'age': 1, '26': 1, '.': 1}, 'sent1': {'construct': 1, 'done': 1, 'mostli': 1, 'local': 1, 'mason': 1, 'carpent': 1, '.': 1}, 'sent2': {'move': 1, 'south': 1, 'pavilion': 1, '1770': 1, '.': 1}, 'sent3': {'turn': 1, 'monticello': 1, 'neoclass': 1, 'masterpiec': 1, 'jefferson': 1, \"'s\": 1, 'obsess': 1, '.': 1}}\n"
     ]
    }
   ],
   "source": [
    "# Loading the corpus into a dictionary\n",
    "corpus ={}\n",
    "for i, sent in enumerate(sentences.split('\\n')):\n",
    "    sentence = sent.lower()                 # Case folding\n",
    "    tokens = tokenizer.tokenize(sentence)   # Tokenisation \n",
    "    stems = [stemmer.stem(token) for token in tokens if token not in stop_words]\n",
    "    \n",
    "    corpus['sent{}'.format(i)] = dict((tok, 1) for tok in stems)\n",
    "\n",
    "print(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thoma</th>\n",
       "      <th>jefferson</th>\n",
       "      <th>began</th>\n",
       "      <th>build</th>\n",
       "      <th>monticello</th>\n",
       "      <th>age</th>\n",
       "      <th>26</th>\n",
       "      <th>.</th>\n",
       "      <th>construct</th>\n",
       "      <th>done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sent0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       thoma  jefferson  began  build  monticello  age  26  .  construct  done\n",
       "sent0      1          1      1      1           1    1   1  1          0     0\n",
       "sent1      0          0      0      0           0    0   0  1          1     1\n",
       "sent2      0          0      0      0           0    0   0  1          0     0\n",
       "sent3      0          1      0      0           1    0   0  1          0     0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the data into a pandas dataframe\n",
    "df = pd.DataFrame.from_records(corpus).fillna(0).astype(int).T\n",
    "\n",
    "df[df.columns[:10]]\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Computing the dot product\n",
    "\n",
    "\"The sum of the products of the corresponding entries of two sequences of numbers\". \n",
    "\n",
    "Let us go and have a look at the [Wikipedia](https://en.wikipedia.org/wiki/Dot_product).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result at iteration 0: 2\n",
      "result at iteration 1: 10\n",
      "result at iteration 2: 28\n",
      "Result: 28\n"
     ]
    }
   ],
   "source": [
    "v1 = np.array([1, 2, 3])\n",
    "v2 = np.array([2, 4, 6])\n",
    "\n",
    "\n",
    "# The long way\n",
    "sum_dot = 0\n",
    "\n",
    "for i in range(len(v1)):\n",
    "    sum_dot += v1[i] * v2[i]\n",
    "    print(\"result at iteration {}: {}\".format(i, sum_dot))\n",
    "print(\"Result:\", sum_dot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "# The smart way (we are \"vectorising\")\n",
    "dot = (v1 * v2).sum()\n",
    "print(dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The numpy way\n",
    "v1.dot(v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dot product can be used to measure the overlap between two documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first need to compute the transpose of the matrix \n",
    "# because I need column vectors\n",
    "\n",
    "df = df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            sent0  sent1  sent2  sent3\n",
      "thoma           1      0      0      0\n",
      "jefferson       1      0      0      1\n",
      "began           1      0      0      0\n",
      "build           1      0      0      0\n",
      "monticello      1      0      0      1\n",
      "age             1      0      0      0\n",
      "26              1      0      0      0\n",
      ".               1      1      1      1\n",
      "construct       0      1      0      0\n",
      "done            0      1      0      0\n",
      "mostli          0      1      0      0\n",
      "local           0      1      0      0\n",
      "mason           0      1      0      0\n",
      "carpent         0      1      0      0\n",
      "move            0      0      1      0\n",
      "south           0      0      1      0\n",
      "pavilion        0      0      1      0\n",
      "1770            0      0      1      0\n",
      "turn            0      0      0      1\n",
      "neoclass        0      0      0      1\n",
      "masterpiec      0      0      0      1\n",
      "'s              0      0      0      1\n",
      "obsess          0      0      0      1\n"
     ]
    }
   ],
   "source": [
    "#How can I print it?\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sent0.dot(df.sent1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sent0.dot(df.sent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sent0.dot(df.sent3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thomas Jefferson began building Monticello at the age of 26.\n",
      "Construction was done mostly by local masons and carpenters.\n",
      "He moved into the South Pavilion in 1770.\n",
      "Turning Monticello into a neoclassical masterpiece was Jefferson's obsession.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('jefferson', 1), ('monticello', 1), ('.', 1)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Where do these numbers come from?\n",
    "print(sentences)\n",
    "[(k, v) for (k, v) in (df.sent0 & df.sent3).items() if v]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is your first **vector space model**!\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
